{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Projeto Final - Noções de Inteligência Artificial 2025/1**\n",
        "## **Alunos**:\n",
        "- Caio Medeiros Balaniuk (matrícula: 231025190)\n",
        "- Davi Henrique Vieira Lima (matrícula: 231013529)\n",
        "- Gabriel Caixeta Romero (matrícula: 232036896)\n",
        "- Vitor Amorim Mello (matrícula: 231037048)\n"
      ],
      "metadata": {
        "id": "E44y2rvRGzkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Instalação da Biblioteca D2L**\n",
        "A biblioteca `D2L` (**Dive Into Deep Learning**) é necessária ser instalada para permitir:\n",
        "  *  Utilitários prontos para carregar e visualizar datasets como MNIST, Fashion-MNIST, entre outros.\n",
        "  *  Funções auxiliares para construir, treinar e avaliar redes neurais em PyTorch.\n",
        "  *  Classes úteis como `DataModule`, `Trainer`, `Classifier`, entre outras, que facilitam o desenvolvimento e experimentação com redes neurais."
      ],
      "metadata": {
        "id": "NjWJq7FpJxyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install d2l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ITaVSokQJzFF",
        "outputId": "65b6765e-1b38-4eb9-a1c7-0919f8e231ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: d2l in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.11/dist-packages (from d2l) (1.0.0)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (from d2l) (1.23.5)\n",
            "Requirement already satisfied: matplotlib==3.7.2 in /usr/local/lib/python3.11/dist-packages (from d2l) (3.7.2)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.11/dist-packages (from d2l) (0.1.6)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.11/dist-packages (from d2l) (2.31.0)\n",
            "Requirement already satisfied: pandas==2.0.3 in /usr/local/lib/python3.11/dist-packages (from d2l) (2.0.3)\n",
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.11/dist-packages (from d2l) (1.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l) (6.5.7)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l) (5.6.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (11.2.1)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (2.9.0.post0)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from matplotlib-inline==0.1.6->d2l) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->d2l) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->d2l) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l) (2025.6.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l) (1.17.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.4.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.0.15)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (2.19.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.8.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l) (25.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.3.1)\n",
            "Requirement already satisfied: qtpy>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from qtconsole->jupyter==1.0.0->d2l) (2.4.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l) (1.4.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (4.24.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l) (4.14.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (0.26.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Importação de Bibliotecas**\n",
        "Para permitir o desenvolvimento do trabalho, é necessário a importação das seguintes bibliotecas:\n",
        "  * `pandas`: principal biblioteca para **manipulação e análise de dados tabulares** (DataFrames).\n",
        "  * `os`: biblioteca para **interagir com o sistema operacional**, útil para manipulação de arquivos e diretórios.\n",
        "  * `gdown`: biblioteca utilizada para **fazer download de arquivos diretamente do Google Drive**, facilitando o carregamento de datasets.\n",
        "  * `zipfile`: módulo padrão do Python para **descompactar arquivos .zip**, usado quando o dataset vem comprimido.\n",
        "  * `torch`: principal biblioteca de **machine learning com PyTorch**.\n",
        "  * `torch from d2l`: apresenta utilitários da biblioteca **Dive into Deep Learning (d2l)** para PyTorch.\n",
        "  * `nn from torch`: módulo de **redes neurais (neural networks)** do PyTorch.\n",
        "  * `train_test_split from sklearn.model_selection`: função para **dividir os dados em conjuntos de treino e teste**, importante para validação do modelo.\n",
        "  * `StandardScaler from sklearn.preprocessing`: usada para **normalizar características numéricas**, garantindo que cada feature tenha média 0 e desvio padrão 1.\n",
        "  * `matplotlib.pyplot`: permite a visualização gráfica do **Matplotlib**."
      ],
      "metadata": {
        "id": "gUFFOgMcJ2Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import gdown\n",
        "import zipfile\n",
        "import torch\n",
        "from d2l import torch as d2l\n",
        "from torch import nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "-9s3VKoNJ7_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Dataset**"
      ],
      "metadata": {
        "id": "IRUJqdLzLUVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.1. Tabela FIPE**\n",
        "O dataset utilizado neste trabalho é composto por dados extraídos da **Tabela Fipe**, que é uma referência oficial no Brasil para a **avaliação de preços médios de veículos automotores** (carros, motos e caminhões).\n",
        "\n",
        "A **Tabela Fipe** é elaborada pela **Fundação Instituto de Pesquisas Econômicas (FIPE)** e fornece mensalmente o **preço médio praticado no mercado nacional para veículos novos e usados**.\n",
        "\n",
        "Cada registro da Tabela Fipe geralmente contém informações como:\n",
        "* **Marca do veículo** (ex: Fiat, Honda, Toyota),\n",
        "\n",
        "* **Modelo do veículo** (ex: Palio 1.0, Civic EXL),\n",
        "\n",
        "* **Ano de fabricação** (anomod),\n",
        "\n",
        "* **Combustível utilizado** (ex: Gasolina, Flex, Diesel),\n",
        "\n",
        "* **Mês/Ano de referência da cotação** (mesref / anoref),\n",
        "\n",
        "* **Valor de mercado estimado** (em reais)."
      ],
      "metadata": {
        "id": "OEkOg8rkTG8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.2. Extração e Organização do Dataset**\n",
        "O conjunto de dados foi gerado utilizando um **web crawler** disponível no repositório [fipe-crawler](https://github.com/rafaelgou/fipe-crawler.git), que automatiza a coleta da Tabela Fipe diretamente do site oficial.\n",
        "\n",
        "Foram coletadas informações dos **últimos 12 meses**, organizadas em múltiplos arquivos CSV (um para cada mês), contendo milhares de registros.\n",
        "\n",
        "Esses arquivos foram agrupados em um **arquivo `.zip` hospedado no Google Drive**, sendo baixados e descompactados automaticamente pelo seguinte trecho de código:"
      ],
      "metadata": {
        "id": "AMqisMTET-uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar o arquivo zip do Google Drive\n",
        "url = \"https://drive.google.com/uc?id=125NtHsqQaokd76-ThXVmQLvLy1vXVd56\"\n",
        "output = \"fipe_dataset.zip\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# Descompactar\n",
        "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"fipe_dataset_extracted\")\n",
        "\n",
        "# Caminho da pasta\n",
        "caminho_pasta = \"/content/fipe_dataset_extracted/dataset\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx3-iYgFtXGk",
        "outputId": "6a735d94-a120-4c2b-bc91-408f0c829942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=125NtHsqQaokd76-ThXVmQLvLy1vXVd56\n",
            "To: /content/fipe_dataset.zip\n",
            "100%|██████████| 187k/187k [00:00<00:00, 51.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.3. Leitura e Pré-processamento Inicial dos Dados**\n",
        "\n",
        "Nesta etapa, realizamos a leitura dos arquivos `.csv` extraídos do arquivo `.zip` contendo os dados mensais da Tabela Fipe.\n",
        "\n",
        "Etapas do processo:\n",
        "\n",
        "1. **Listagem dos Arquivos:** Todos os arquivos dentro do diretório da base são listados e ordenados alfabeticamente para garantir consistência na leitura.\n",
        "\n",
        "2. **Leitura de Cada Arquivo CSV:** Cada arquivo `.csv` é lido individualmente utilizando o `pandas.read_csv`. Caso haja erro na leitura de algum arquivo (ex: linhas mal formatadas), ele será ignorado com a opção `on_bad_lines=\"skip\"`.\n",
        "\n",
        "3. **Concatenação dos Dados:** Todos os DataFrames lidos são concatenados em um único DataFrame chamado `dados`, unificando todos os registros coletados ao longo dos meses.\n",
        "\n",
        "4. **Criação da Coluna `timeprod`:** Essa coluna representa o tempo de produção do veículo (em meses) desde seu ano de fabricação (`anomod`) até o ano e mês de referência (`anoref`, `mesref`).\n",
        "\n",
        "5. **Seleção de Colunas Relevantes:** Apenas as colunas de interesse são mantidas para a análise: marca, modelo, ano de fabricação, tipo de combustível, tempo de produção e valor.\n",
        "\n",
        "6. **Filtragem de Registros com Valores Realistas:** São removidos registros com anos ou tempos de produção considerados fora do intervalo aceitável (anomalias ou erros de coleta).\n",
        "\n",
        "7. **Remoção de Duplicatas:** Garante que não haja linhas repetidas no conjunto final.\n",
        "\n",
        "8. **Exibição Final:** Apresenta o DataFrame resultante com os dados prontos para o pré-processamento posterior e uso em modelos de aprendizado de máquina.\n",
        "\n"
      ],
      "metadata": {
        "id": "xU5BG0kiVj28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arquivos = sorted(os.listdir(caminho_pasta))\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for arquivo in arquivos:\n",
        "    caminho_arquivo = os.path.join(caminho_pasta, arquivo)\n",
        "    try:\n",
        "        df = pd.read_csv(caminho_arquivo, engine=\"python\", on_bad_lines=\"skip\")\n",
        "        dfs.append(df)\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao ler {arquivo}: {e}\")\n",
        "\n",
        "dados = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "dados[\"timeprod\"] = (dados[\"anoref\"] - dados[\"anomod\"]) * 12 + (dados[\"mesref\"] - 1)\n",
        "\n",
        "dados_final = dados[[\"marca\", \"modelo\", \"anomod\", \"comb\", \"timeprod\", \"valor\"]]\n",
        "\n",
        "dados_filtrados = dados_final[\n",
        "    (dados_final[\"anomod\"] >= 1980) & (dados_final[\"anomod\"] <= 2025) &\n",
        "    (dados_final[\"timeprod\"] >= 0) & (dados_final[\"timeprod\"] <= 600)\n",
        "]\n",
        "\n",
        "dt = dados_filtrados.drop_duplicates()\n",
        "\n",
        "print(dt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy6MzYQ7jf_l",
        "outputId": "2bf25a1f-acec-4726-aa79-6407e1da3ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                marca                                    modelo  anomod  \\\n",
            "0                Audi  A4 2.0 Avant Ambie. 2.0 16V TFSi S tron.    2018   \n",
            "1                Audi  A4 2.0 Avant Ambie. 2.0 16V TFSi S tron.    2017   \n",
            "2                Audi                           A4 2.8 30V Mec.    2001   \n",
            "3                Audi           A4 3.0 30V 218cv Multitronic 4p    2006   \n",
            "4                Audi           A4 3.0 30V 218cv Multitronic 4p    2004   \n",
            "...               ...                                       ...     ...   \n",
            "9351  VW - VolksWagen      VOYAGE TREND 1.6 Mi Total Flex 8V 4p    2009   \n",
            "9353             Wake                Way 1.6 Total Flex 8V Mec.    2016   \n",
            "9354             Wake                Way 1.6 Total Flex 8V Mec.    2012   \n",
            "9355             Wake                Way 1.6 Total Flex 8V Mec.    2010   \n",
            "9356             Wake                Way 1.8 Total Flex 8V Mec.    2010   \n",
            "\n",
            "          comb  timeprod   valor  \n",
            "0     Gasolina        81  144961  \n",
            "1     Gasolina        93  139126  \n",
            "2     Gasolina       285   22978  \n",
            "3     Gasolina       225   52478  \n",
            "4     Gasolina       249   38999  \n",
            "...        ...       ...     ...  \n",
            "9351  Gasolina       198   27652  \n",
            "9353  Gasolina       114   53117  \n",
            "9354  Gasolina       162   30310  \n",
            "9355  Gasolina       186   20514  \n",
            "9356  Gasolina       186   21393  \n",
            "\n",
            "[9098 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Separar features (X) e alvo (y)\n",
        "df = dt.dropna()\n",
        "X = df.drop('valor', axis=1)\n",
        "y = df['valor']\n",
        "\n",
        "# 2. Dividir os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Pré-processamento dos dados\n",
        "categorical_features = ['marca', 'modelo', 'comb']\n",
        "numerical_features = ['anomod', 'timeprod']\n",
        "\n",
        "# --- Processando os dados de TREINO ---\n",
        "scaler = StandardScaler()\n",
        "X_train_numerical_scaled = scaler.fit_transform(X_train[numerical_features])\n",
        "X_train_numerical = pd.DataFrame(X_train_numerical_scaled, columns=numerical_features, index=X_train.index)\n",
        "X_train_categorical = pd.get_dummies(X_train[categorical_features], drop_first=True)\n",
        "X_train_processed = pd.concat([X_train_numerical, X_train_categorical], axis=1)\n",
        "\n",
        "# --- Processando os dados de TESTE ---\n",
        "X_test_numerical_scaled = scaler.transform(X_test[numerical_features])\n",
        "X_test_numerical = pd.DataFrame(X_test_numerical_scaled, columns=numerical_features, index=X_test.index)\n",
        "X_test_categorical = pd.get_dummies(X_test[categorical_features], drop_first=True)\n",
        "X_test_processed = pd.concat([X_test_numerical, X_test_categorical], axis=1)\n",
        "\n",
        "\n",
        "X_test_processed = X_test_processed.reindex(columns=X_train_processed.columns, fill_value=0)\n",
        "\n",
        "# 4. Conversão para Tensores PyTorch\n",
        "\n",
        "# FORÇA a conversão de todos os dados para float32 ANTES de criar o tensor.\n",
        "# Isso resolve o problema de conversão do NumPy.\n",
        "# Usamos .to_numpy() que é a forma moderna e recomendada no lugar de .values\n",
        "X_train_tensor = torch.tensor(X_train_processed.astype('float32').to_numpy())\n",
        "y_train_tensor = torch.tensor(y_train.astype('float32').to_numpy()).view(-1, 1)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test_processed.astype('float32').to_numpy())\n",
        "y_test_tensor = torch.tensor(y_test.astype('float32').to_numpy()).view(-1, 1)\n",
        "\n",
        "print(X_train_tensor.shape)\n",
        "print(y_train_tensor.shape)\n",
        "print(X_test_tensor.shape)\n",
        "print(y_test_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaSuhL3mzYVV",
        "outputId": "1ab3a0f9-d163-49ae-c88e-26b34f66b89b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7278, 3369])\n",
            "torch.Size([7278, 1])\n",
            "torch.Size([1820, 3369])\n",
            "torch.Size([1820, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Modelos**"
      ],
      "metadata": {
        "id": "JGTYDhvZId3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression(d2l.Module):\n",
        "    \"\"\"The linear regression model implemented with high-level APIs.\"\"\"\n",
        "    def __init__(self, lr):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.LazyLinear(1)\n",
        "        self.net.weight.data.normal_(0, 0.01)\n",
        "        self.net.bias.data.fill_(0)"
      ],
      "metadata": {
        "id": "d7C5bmlyIf9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@d2l.add_to_class(LinearRegression)\n",
        "def forward(self, X):\n",
        "    return self.net(X)"
      ],
      "metadata": {
        "id": "ZzwITG59JAVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@d2l.add_to_class(LinearRegression)\n",
        "def loss(self, y_hat, y):\n",
        "    fn = nn.MSELoss()\n",
        "    return fn(y_hat, y)"
      ],
      "metadata": {
        "id": "cj3XVaLyJFRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@d2l.add_to_class(LinearRegression)\n",
        "def configure_optimizers(self):\n",
        "    return torch.optim.SGD(self.parameters(), self.lr)"
      ],
      "metadata": {
        "id": "2oqLeScPJHCM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}